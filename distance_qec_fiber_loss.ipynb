{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "003880ff-bc35-4152-8066-909c5ba4106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import AutoMinorLocator, MultipleLocator\n",
    "import matplotlib as mpl\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "# --- Configuration ---\n",
    "# Make sure this points to the correct directory containing the distance experiment results\n",
    "RESULTS_DIR = \"distance_qec_fiber_loss\"\n",
    "PLOTS_DIR = \"plots_distance_qec_fiber_loss\"\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "# --- Plotting Configuration (Copied from single_qubit_analysis.py) ---\n",
    "def configure_plots():\n",
    "    \"\"\"Configure matplotlib rcParams for publication-quality plots\"\"\"\n",
    "    plt.style.use('seaborn-v0_8-whitegrid') # Use an available style\n",
    "    mpl.rcParams.update({\n",
    "        'font.family': 'serif',\n",
    "        'font.size': 12,\n",
    "        'axes.labelsize': 14,\n",
    "        'axes.titlesize': 16,\n",
    "        'xtick.labelsize': 12,\n",
    "        'ytick.labelsize': 12,\n",
    "        'legend.fontsize': 10, # Adjusted legend size\n",
    "        'legend.frameon': True,\n",
    "        'legend.framealpha': 0.8,\n",
    "        'figure.figsize': (12, 7), # Slightly wider default\n",
    "        'figure.dpi': 300,\n",
    "        'text.usetex': False,  # Keep False for broader compatibility\n",
    "        'mathtext.fontset': 'stix',\n",
    "        'axes.prop_cycle': plt.cycler('color', plt.cm.viridis(np.linspace(0, 0.85, 8))),\n",
    "        'axes.axisbelow': True,\n",
    "        'grid.alpha': 0.6,\n",
    "        'grid.linestyle': ':'\n",
    "    })\n",
    "\n",
    "configure_plots() # Apply the configuration\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning) # Ignore potential runtime warnings from mean of empty slice\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def format_gamma(value, precision=4):\n",
    "    \"\"\"Formats gamma values, truncating long decimals.\"\"\"\n",
    "    if isinstance(value, (int, float)):\n",
    "        if abs(value - round(value)) < 1e-9: # Check if it's effectively an integer\n",
    "             return str(int(value))\n",
    "        else:\n",
    "             # Truncate instead of round\n",
    "             factor = 10.0 ** precision\n",
    "             return str(math.trunc(value * factor) / factor)\n",
    "             # Alternative: standard formatting\n",
    "             # return f\"{value:.{precision}g}\"\n",
    "    return str(value)\n",
    "\n",
    "def parse_param_string_distance(param_str):\n",
    "    \"\"\"Parses complex parameter strings from distance experiments.\n",
    "       Handles p_loss_init, p_loss_length, sec_gamma, ter_gamma etc.\n",
    "    \"\"\"\n",
    "    params = {}\n",
    "    parts = param_str.split('_')\n",
    "    i = 0\n",
    "    current_key = \"\"\n",
    "    while i < len(parts):\n",
    "        part = parts[i]\n",
    "        # Check if the part looks like a value (numeric, possibly with decimal or E notation)\n",
    "        is_value = False\n",
    "        try:\n",
    "            float(part)\n",
    "            is_value = True\n",
    "        except ValueError:\n",
    "            is_value = False\n",
    "\n",
    "        if not is_value and current_key:\n",
    "            # If we have a key and the current part isn't a value, it's part of the key\n",
    "            current_key += \"_\" + part\n",
    "            i += 1\n",
    "        elif not is_value and not current_key:\n",
    "            # Starting a new key\n",
    "            current_key = part\n",
    "            i += 1\n",
    "        elif is_value and current_key:\n",
    "            # Found the value for the current key\n",
    "            try:\n",
    "                 params[current_key] = float(part)\n",
    "            except ValueError:\n",
    "                 params[current_key] = part # Keep as string if not float\n",
    "            current_key = \"\" # Reset key\n",
    "            i += 1\n",
    "        else:\n",
    "            # Edge case: value without a preceding key? Or starting with a value?\n",
    "            # Treat as part of the next key or ignore if error\n",
    "            # print(f\"Warning: Unexpected part '{part}' in param string: {param_str}\")\n",
    "            i += 1 # Move on\n",
    "\n",
    "    # Rename keys for clarity if needed (optional)\n",
    "    final_params = {}\n",
    "    for k, v in params.items():\n",
    "        if k.startswith(\"sec_\"):\n",
    "            final_params[k] = v # Keep prefix for now\n",
    "        elif k.startswith(\"ter_\"):\n",
    "            final_params[k] = v # Keep prefix for now\n",
    "        else:\n",
    "            final_params[k] = v\n",
    "\n",
    "    return final_params\n",
    "\n",
    "def format_params_dict(params_dict):\n",
    "    \"\"\"Creates a readable string representation of the params dict, formatting gamma.\"\"\"\n",
    "    if not params_dict:\n",
    "        return \"No Params\"\n",
    "    items = []\n",
    "    for k, v in sorted(params_dict.items()):\n",
    "        if 'gamma' in k:\n",
    "            items.append(f\"{k}={format_gamma(v)}\")\n",
    "        else:\n",
    "            items.append(f\"{k}={v}\")\n",
    "    return \", \".join(items)\n",
    "\n",
    "# --- Data Loading Function --- \n",
    "def load_distance_qec_data(results_dir=RESULTS_DIR):\n",
    "    \"\"\"\n",
    "    Loads experiment data from the distance_qec_network results structure.\n",
    "    Extracts metrics from metadata files and calculates loss-adjusted fidelity.\n",
    "    \"\"\"\n",
    "    print(f\"Loading distance experiment data from: {results_dir}\")\n",
    "    all_experiments_data = []\n",
    "    skipped_files = []\n",
    "    loaded_count = 0\n",
    "    file_parse_errors = []\n",
    "\n",
    "    # Regex to capture: state, qec_method, distance, params_string\n",
    "    # Example: +_none_d10.0_p_loss_init_0.05_p_loss_length_0.16_sec_gamma_0.01_ter_gamma_0.2.csv\n",
    "    filename_pattern = re.compile(r\"^([+\\-01])_(.+?)_d([\\d\\.]+?)_(.+)\\.csv$\")\n",
    "\n",
    "    # Iterate through error combination directories\n",
    "    error_combo_dirs = [d for d in os.listdir(results_dir) if os.path.isdir(os.path.join(results_dir, d))]\n",
    "\n",
    "    for error_combo in error_combo_dirs:\n",
    "        dir_path = os.path.join(results_dir, error_combo)\n",
    "        # print(f\" Processing directory: {dir_path}\") # Reduced verbosity\n",
    "\n",
    "        for filename in os.listdir(dir_path):\n",
    "            # Focus ONLY on metadata files for primary data extraction\n",
    "            if not filename.endswith(\"_metadata.csv\"):\n",
    "                continue\n",
    "\n",
    "            base_filename = filename.replace(\"_metadata.csv\", \".csv\")\n",
    "            match = filename_pattern.match(base_filename)\n",
    "\n",
    "            if match:\n",
    "                initial_state = match.group(1)\n",
    "                qec_method = match.group(2)\n",
    "                distance = float(match.group(3))\n",
    "                param_string = match.group(4)\n",
    "                metadata_path = os.path.join(dir_path, filename)\n",
    "\n",
    "                try:\n",
    "                    # Parse the parameter string first\n",
    "                    error_params = parse_param_string_distance(param_string)\n",
    "                    if not error_params:\n",
    "                        # print(f\"  - Warning: Could not parse parameters from '{param_string}' in {base_filename}\")\n",
    "                        skipped_files.append(base_filename)\n",
    "                        continue\n",
    "\n",
    "                    # Load metadata\n",
    "                    metadata_df = pd.read_csv(metadata_path)\n",
    "                    if metadata_df.empty:\n",
    "                        # print(f\"  - Warning: Empty metadata file: {filename}\")\n",
    "                        skipped_files.append(base_filename)\n",
    "                        continue\n",
    "                    metadata = metadata_df.iloc[0].to_dict()\n",
    "\n",
    "                    # Extract required fields from metadata\n",
    "                    raw_avg_fidelity = metadata.get('avg_fidelity', 0.0)\n",
    "                    raw_std_fidelity = metadata.get('std_fidelity', 0.0)\n",
    "                    total_runs = metadata.get('iterations_completed', 0)\n",
    "                    loss_count = metadata.get('loss_count', 0)\n",
    "\n",
    "                    # Calculate loss-adjusted metrics\n",
    "                    loss_adjusted_avg_fidelity = 0.0\n",
    "                    loss_ratio = 0.0\n",
    "                    successful_runs = total_runs - loss_count\n",
    "\n",
    "                    if total_runs > 0:\n",
    "                        loss_ratio = loss_count / total_runs\n",
    "                        # Adjust fidelity: assume lost runs have fidelity 0\n",
    "                        # Also handle case where raw_avg_fidelity is NaN (if successful_runs is 0)\n",
    "                        if successful_runs > 0 and pd.notna(raw_avg_fidelity):\n",
    "                             loss_adjusted_avg_fidelity = (raw_avg_fidelity * successful_runs) / total_runs\n",
    "                        else:\n",
    "                             loss_adjusted_avg_fidelity = 0.0 # If no successful runs or raw fidelity is NaN\n",
    "\n",
    "                    else:\n",
    "                         # Handle case with 0 iterations completed? Set fidelities to 0.\n",
    "                         raw_avg_fidelity = 0.0\n",
    "                         raw_std_fidelity = 0.0\n",
    "                         loss_adjusted_avg_fidelity = 0.0\n",
    "\n",
    "                    experiment_entry = {\n",
    "                         \"initial_state\": initial_state,\n",
    "                         \"qec_method\": qec_method,\n",
    "                         \"distance\": distance,\n",
    "                         \"error_combo\": error_combo, # Store the directory name as the error combo identifier\n",
    "                         \"error_params\": error_params,\n",
    "                         \"param_string\": format_params_dict(error_params), # Store readable param string\n",
    "                         \"avg_fidelity_raw\": raw_avg_fidelity,\n",
    "                         \"std_fidelity_raw\": raw_std_fidelity, # Std dev of individual trial fidelities (from metadata)\n",
    "                         \"avg_fidelity_adj\": loss_adjusted_avg_fidelity,\n",
    "                         \"loss_ratio\": loss_ratio,\n",
    "                         \"loss_count\": loss_count,\n",
    "                         \"total_runs\": total_runs,\n",
    "                         \"filename_base\": base_filename\n",
    "                         # We are not loading the full data CSV by default here\n",
    "                    }\n",
    "\n",
    "                    all_experiments_data.append(experiment_entry)\n",
    "                    loaded_count += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"  - Error processing metadata file {filename}: {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc() # Print traceback for debugging loading errors\n",
    "                    file_parse_errors.append((filename, str(e)))\n",
    "                    skipped_files.append(base_filename)\n",
    "            else:\n",
    "                 # Metadata filename doesn't match expected base pattern\n",
    "                 skipped_files.append(filename)\n",
    "\n",
    "    print(f\"Finished loading. Loaded {loaded_count} experiment configurations from metadata.\")\n",
    "    if skipped_files:\n",
    "        print(f\"Skipped {len(skipped_files)} files/metadata (check format/content/errors).\")\n",
    "    if file_parse_errors:\n",
    "        print(f\"Encountered {len(file_parse_errors)} errors during file processing:\")\n",
    "        for fname, err in file_parse_errors[:10]:\n",
    "             print(f\"  - {fname}: {err}\")\n",
    "        if len(file_parse_errors) > 10:\n",
    "             print(\"  ... (additional errors truncated)\")\n",
    "    return all_experiments_data\n",
    "\n",
    "# ===========================================\n",
    "# --- NEW Plotting Functions Implementation ---\n",
    "# ===========================================\n",
    "\n",
    "# --- Mappings for Plotting ---\n",
    "ERROR_COMBO_MAP = {\n",
    "    'fibre_loss': 'Fiber',\n",
    "    'fibre_loss_plus_amplitude_damping': 'Fiber+Amp',\n",
    "    'fibre_loss_plus_phase_damping': 'Fiber+Phase',\n",
    "    'fibre_loss_plus_amplitude_damping_plus_phase_damping': 'Fiber+Amp+Phase'\n",
    "}\n",
    "\n",
    "METHOD_DISPLAY_MAP = {\n",
    "    'none': 'No QEC',\n",
    "    'three_qubit_phase_flip': '3QB Phase',\n",
    "    'shor_nine': 'Shor-9' # Add other methods if present\n",
    "}\n",
    "\n",
    "# --- Plot 1: Fidelity (Raw & Adjusted) vs Error Combination ---\n",
    "def plot_fidelity_by_error_combo(df, plots_subdir=\"1_fidelity_vs_error_combo\"):\n",
    "    \"\"\"\n",
    "    Plots avg fidelity (raw & adjusted) vs. error combination.\n",
    "    Averages over distances, QEC methods, initial states, and specific parameters.\n",
    "    Includes std dev of the *mean* fidelities across aggregated groups.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Plot 1: Fidelity vs Error Combination ---\")\n",
    "    plot_dir = os.path.join(PLOTS_DIR, plots_subdir)\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "    # Aggregate fidelities, calculating mean and std dev of the means across runs\n",
    "    agg_data = df.groupby('error_combo').agg(\n",
    "        mean_raw=('avg_fidelity_raw', 'mean'),\n",
    "        std_raw=('avg_fidelity_raw', 'std'), # Std dev of the mean fidelities from different configs\n",
    "        mean_adj=('avg_fidelity_adj', 'mean'),\n",
    "        std_adj=('avg_fidelity_adj', 'std')  # Std dev of the mean adjusted fidelities\n",
    "    ).reset_index()\n",
    "\n",
    "    # Sort for consistent plotting order (optional)\n",
    "    agg_data = agg_data.sort_values(by='mean_adj', ascending=False)\n",
    "\n",
    "    if agg_data.empty:\n",
    "        print(\"  No data to plot for Fidelity vs Error Combination.\")\n",
    "        return\n",
    "\n",
    "    n_combos = len(agg_data['error_combo'])\n",
    "    index = np.arange(n_combos)\n",
    "    bar_width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(max(10, n_combos * 1.5), 7)) # Adjust width based on number of combos\n",
    "\n",
    "    # Plot bars\n",
    "    bars_raw = ax.bar(index - bar_width/2, agg_data['mean_raw'], bar_width,\n",
    "                      yerr=agg_data['std_raw'], label=r'Raw Fidelity',\n",
    "                      capsize=4, alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "    bars_adj = ax.bar(index + bar_width/2, agg_data['mean_adj'], bar_width,\n",
    "                      yerr=agg_data['std_adj'], label=r'Loss-Adjusted Fidelity',\n",
    "                      capsize=4, alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "    # Add labels and title with LaTeX\n",
    "    ax.set_xlabel(r'Error Combination')\n",
    "    ax.set_ylabel(r'Average Fidelity $F$')\n",
    "    ax.set_title(r'Overall Average Fidelity by Error Combination')\n",
    "    ax.set_xticks(index)\n",
    "    # Use the mapped short names for labels\n",
    "    ax.set_xticklabels(agg_data['error_combo'], rotation=30, ha='right')\n",
    "    ax.legend(loc='upper right') # Changed from 'best'\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.grid(axis='y', linestyle=':', alpha=0.7)\n",
    "    ax.yaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "\n",
    "    # Add value labels on top of bars (optional, can be cluttered)\n",
    "    # ax.bar_label(bars_raw, fmt=r'%.2f', padding=3, fontsize=8)\n",
    "    # ax.bar_label(bars_adj, fmt=r'%.2f', padding=3, fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, \"avg_fidelity_by_error_combo.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# --- Plot 2: Fidelity/Loss vs Fiber Parameters --- (REMOVED)\n",
    "# def plot_fidelity_loss_vs_fiber_params(df, plots_subdir=\"2_vs_fiber_params\"):\n",
    "#     ...\n",
    "\n",
    "# --- Plot 3: Fidelity (Raw & Adjusted) vs Distance (Combined) ---\n",
    "def plot_fidelity_vs_distance_combined(df, plots_subdir=\"2_fidelity_vs_distance_combined\"):\n",
    "    \"\"\"Creates a single plot showing fidelity vs distance for all error combinations.\"\"\"\n",
    "    print(\"\\n--- Plotting Fidelity vs. Distance (Combined) ---\")\n",
    "    plot_dir = os.path.join(PLOTS_DIR, plots_subdir)\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    \n",
    "    # Filter out too-few points\n",
    "    distances = sorted(df['distance'].unique())\n",
    "    if len(distances) <= 1:\n",
    "        print(\"  Not enough distance points to create plot.\")\n",
    "        return\n",
    "    \n",
    "    # Create a single plot instead of 4 subplots\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # Set up color scheme by error combination\n",
    "    error_combos = sorted(df['error_combo'].unique())\n",
    "    colors = plt.cm.viridis(np.linspace(0, 0.85, len(error_combos)))\n",
    "    error_colors = {combo: colors[i] for i, combo in enumerate(error_combos)}\n",
    "    \n",
    "    # Set up marker scheme by QEC method\n",
    "    qec_methods = sorted(df['qec_method'].unique())\n",
    "    markers = ['o', 's', '^', 'd', '*']\n",
    "    marker_map = {qec: markers[i % len(markers)] for i, qec in enumerate(qec_methods)}\n",
    "    \n",
    "    # Track lines for legend\n",
    "    error_lines = {}\n",
    "    method_markers = {}\n",
    "    \n",
    "    # Plot each error combination and QEC method\n",
    "    for error_combo in error_combos:\n",
    "        for qec_method in qec_methods:\n",
    "            subset = df[(df['error_combo'] == error_combo) & \n",
    "                        (df['qec_method'] == qec_method)]\n",
    "            \n",
    "            if subset.empty:\n",
    "                continue\n",
    "                \n",
    "            # Average across other parameters for each distance\n",
    "            avg_by_dist = subset.groupby('distance').agg(\n",
    "                avg_fid_raw=('avg_fidelity_raw', 'mean'),\n",
    "                std_fid_raw=('avg_fidelity_raw', 'std'),\n",
    "                avg_fid_adj=('avg_fidelity_adj', 'mean'),\n",
    "                std_fid_adj=('avg_fidelity_adj', 'std')\n",
    "            ).reset_index()\n",
    "            \n",
    "            if avg_by_dist.empty or len(avg_by_dist) < 2:\n",
    "                continue\n",
    "                \n",
    "            # Plot raw fidelity (solid line)\n",
    "            line_raw, = ax.plot(avg_by_dist['distance'], avg_by_dist['avg_fid_raw'],\n",
    "                             marker=marker_map[qec_method], linestyle='-', linewidth=2,\n",
    "                             color=error_colors[error_combo], markersize=8,\n",
    "                             label=f\"{ERROR_COMBO_MAP.get(error_combo, error_combo)} - {METHOD_DISPLAY_MAP.get(qec_method, qec_method)} (Raw)\")\n",
    "            \n",
    "            # Plot adjusted fidelity (dashed line)\n",
    "            line_adj, = ax.plot(avg_by_dist['distance'], avg_by_dist['avg_fid_adj'],\n",
    "                             marker=marker_map[qec_method], linestyle='--', linewidth=2, \n",
    "                             color=error_colors[error_combo], markersize=8,\n",
    "                             label=f\"{ERROR_COMBO_MAP.get(error_combo, error_combo)} - {METHOD_DISPLAY_MAP.get(qec_method, qec_method)} (Adj.)\")\n",
    "            \n",
    "            # Add error bars\n",
    "            ax.fill_between(avg_by_dist['distance'], \n",
    "                          avg_by_dist['avg_fid_raw'] - avg_by_dist['std_fid_raw'],\n",
    "                          avg_by_dist['avg_fid_raw'] + avg_by_dist['std_fid_raw'], \n",
    "                          color=error_colors[error_combo], alpha=0.1)\n",
    "            \n",
    "            ax.fill_between(avg_by_dist['distance'], \n",
    "                          avg_by_dist['avg_fid_adj'] - avg_by_dist['std_fid_adj'],\n",
    "                          avg_by_dist['avg_fid_adj'] + avg_by_dist['std_fid_adj'], \n",
    "                          color=error_colors[error_combo], alpha=0.1)\n",
    "            \n",
    "            # Track for legend\n",
    "            error_combo_name = ERROR_COMBO_MAP.get(error_combo, error_combo)\n",
    "            if error_combo_name not in error_lines:\n",
    "                error_lines[error_combo_name] = line_raw\n",
    "            \n",
    "            method_name = METHOD_DISPLAY_MAP.get(qec_method, qec_method)\n",
    "            if method_name not in method_markers:\n",
    "                method_markers[method_name] = marker_map[qec_method]\n",
    "    \n",
    "    # Set up plot appearance\n",
    "    ax.set_title(\"Fidelity vs. Distance by Error Combination\", fontsize=16)\n",
    "    ax.set_xlabel(\"Distance (km)\", fontsize=14)\n",
    "    ax.set_ylabel(\"Average Fidelity\", fontsize=14)\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.set_xlim(left=0)\n",
    "    ax.grid(True, linestyle=':', alpha=0.7)\n",
    "    \n",
    "    # Create a better legend\n",
    "    from matplotlib.lines import Line2D\n",
    "    \n",
    "    # Create custom legend elements\n",
    "    legend_elements = []\n",
    "    \n",
    "    # Add error types\n",
    "    for name, line in error_lines.items():\n",
    "        legend_elements.append(Line2D([0], [0], color=line.get_color(), lw=2, label=name))\n",
    "    \n",
    "    # Add line styles\n",
    "    legend_elements.append(Line2D([0], [0], color='gray', lw=2, linestyle='-', label='Raw Fidelity'))\n",
    "    legend_elements.append(Line2D([0], [0], color='gray', lw=2, linestyle='--', label='Adj. Fidelity'))\n",
    "    \n",
    "    # Add QEC methods\n",
    "    for name, marker in method_markers.items():\n",
    "        legend_elements.append(Line2D([0], [0], marker=marker, color='gray', linestyle='None',\n",
    "                                     markersize=8, label=name))\n",
    "    \n",
    "    ax.legend(handles=legend_elements, loc='best', fontsize=10, framealpha=0.9,\n",
    "             bbox_to_anchor=(1.02, 1), borderaxespad=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, \"fidelity_vs_distance_all.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# --- Plot 4: QEC Performance (Raw & Adjusted) vs Error Combination (Faceted by Error Combo) ---\n",
    "def plot_qec_performance_faceted_by_error(df, plots_subdir=\"3_qec_performance_faceted_by_error\"):\n",
    "    \"\"\"\n",
    "    Plots raw and adjusted fidelity vs. QEC method, faceted by error combination.\n",
    "    Includes std dev error bars representing variation across parameters/distances.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Plot 3: QEC Performance (Faceted by Error Combo) ---\")\n",
    "    plot_dir = os.path.join(PLOTS_DIR, plots_subdir)\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "    qec_methods = sorted(df['qec_method'].unique())\n",
    "    error_combos = sorted(df['error_combo'].unique())\n",
    "    # Use METHOD_DISPLAY_MAP defined globally\n",
    "\n",
    "    # Determine grid size\n",
    "    n_combos = len(error_combos)\n",
    "    n_cols = 2\n",
    "    n_rows = (n_combos + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(7 * n_cols, 5 * n_rows), sharex=True, sharey=True, squeeze=False)\n",
    "    axs_flat = axs.flatten()\n",
    "\n",
    "    for i, error_combo in enumerate(error_combos):\n",
    "        ax = axs_flat[i]\n",
    "        combo_subset = df[df['error_combo'] == error_combo]\n",
    "\n",
    "        # Aggregate fidelities for this error combo\n",
    "        agg_data = combo_subset.groupby('qec_method').agg(\n",
    "            mean_raw=('avg_fidelity_raw', 'mean'),\n",
    "            std_raw=('avg_fidelity_raw', 'std'),\n",
    "            mean_adj=('avg_fidelity_adj', 'mean'),\n",
    "            std_adj=('avg_fidelity_adj', 'std')\n",
    "        ).reindex(qec_methods) # Ensure all methods are present and ordered\n",
    "\n",
    "        if agg_data.empty:\n",
    "             ax.text(0.5, 0.5, 'No Data', ha='center', va='center', transform=ax.transAxes)\n",
    "             ax.set_title(error_combo)\n",
    "             continue\n",
    "\n",
    "        n_methods_local = len(agg_data.index)\n",
    "        index = np.arange(n_methods_local)\n",
    "        bar_width = 0.35\n",
    "\n",
    "        # Plot bars\n",
    "        bars_raw = ax.bar(index - bar_width/2, agg_data['mean_raw'], bar_width,\n",
    "                          yerr=agg_data['std_raw'], label=r'Raw Fidelity',\n",
    "                          capsize=3, alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "        bars_adj = ax.bar(index + bar_width/2, agg_data['mean_adj'], bar_width,\n",
    "                          yerr=agg_data['std_adj'], label=r'Loss-Adjusted Fidelity',\n",
    "                          capsize=3, alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "        ax.set_title(error_combo) # Use mapped short name\n",
    "        ax.set_xticks(index)\n",
    "        # Use METHOD_DISPLAY_MAP for labels\n",
    "        ax.set_xticklabels([METHOD_DISPLAY_MAP.get(m, m) for m in agg_data.index], rotation=30, ha='right')\n",
    "        ax.set_ylim(0, 1.05)\n",
    "        ax.grid(axis='y', linestyle=':', alpha=0.7)\n",
    "        ax.yaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "\n",
    "        if i % n_cols == 0: # Only first column\n",
    "             ax.set_ylabel(r'Average Fidelity $F$')\n",
    "        if i == 0: # Add legend to the first plot\n",
    "            ax.legend(loc='best', fontsize=9)\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for j in range(i + 1, n_rows * n_cols):\n",
    "        axs_flat[j].set_visible(False)\n",
    "\n",
    "    fig.suptitle(r'QEC Method Performance Across Error Combinations', fontsize=18, y=1.02)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 1]) # Adjust rect\n",
    "    plt.savefig(os.path.join(plot_dir, \"qec_performance_faceted_by_error.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# --- Plot 5: Loss Ratio vs Distance (Combined) ---\n",
    "def plot_loss_vs_distance_combined(df, plots_subdir=\"4_loss_vs_distance_combined\"):\n",
    "    \"\"\"Creates a single plot showing loss ratio vs distance for all error combinations.\"\"\"\n",
    "    print(\"\\n--- Plotting Loss Ratio vs. Distance (Combined) ---\")\n",
    "    plot_dir = os.path.join(PLOTS_DIR, plots_subdir)\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    \n",
    "    # Filter out too-few points\n",
    "    distances = sorted(df['distance'].unique())\n",
    "    if len(distances) <= 1:\n",
    "        print(\"  Not enough distance points to create plot.\")\n",
    "        return\n",
    "    \n",
    "    # Create a single plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # Set up color scheme by error combination\n",
    "    error_combos = sorted(df['error_combo'].unique())\n",
    "    colors = plt.cm.viridis(np.linspace(0, 0.85, len(error_combos)))\n",
    "    error_colors = {combo: colors[i] for i, combo in enumerate(error_combos)}\n",
    "    \n",
    "    # Set up marker scheme by QEC method\n",
    "    qec_methods = sorted(df['qec_method'].unique())\n",
    "    markers = ['o', 's', '^', 'd', '*']\n",
    "    marker_map = {qec: markers[i % len(markers)] for i, qec in enumerate(qec_methods)}\n",
    "    \n",
    "    # Track lines for legend\n",
    "    error_lines = {}\n",
    "    method_markers = {}\n",
    "    \n",
    "    # Plot each error combination and QEC method\n",
    "    for error_combo in error_combos:\n",
    "        for qec_method in qec_methods:\n",
    "            subset = df[(df['error_combo'] == error_combo) & \n",
    "                        (df['qec_method'] == qec_method)]\n",
    "            \n",
    "            if subset.empty:\n",
    "                continue\n",
    "                \n",
    "            # Average across other parameters for each distance\n",
    "            avg_by_dist = subset.groupby('distance').agg(\n",
    "                avg_loss=('loss_ratio', 'mean'),\n",
    "                std_loss=('loss_ratio', 'std')\n",
    "            ).reset_index()\n",
    "            \n",
    "            if avg_by_dist.empty or len(avg_by_dist) < 2:\n",
    "                continue\n",
    "                \n",
    "            # Plot loss ratio\n",
    "            line, = ax.plot(avg_by_dist['distance'], avg_by_dist['avg_loss'],\n",
    "                          marker=marker_map[qec_method], linestyle='-', linewidth=2,\n",
    "                          color=error_colors[error_combo], markersize=8,\n",
    "                          label=f\"{ERROR_COMBO_MAP.get(error_combo, error_combo)} - {METHOD_DISPLAY_MAP.get(qec_method, qec_method)}\")\n",
    "            \n",
    "            # Add error bars\n",
    "            ax.fill_between(avg_by_dist['distance'], \n",
    "                          avg_by_dist['avg_loss'] - avg_by_dist['std_loss'],\n",
    "                          avg_by_dist['avg_loss'] + avg_by_dist['std_loss'], \n",
    "                          color=error_colors[error_combo], alpha=0.1)\n",
    "            \n",
    "            # Track for legend\n",
    "            error_combo_name = ERROR_COMBO_MAP.get(error_combo, error_combo)\n",
    "            if error_combo_name not in error_lines:\n",
    "                error_lines[error_combo_name] = line\n",
    "            \n",
    "            method_name = METHOD_DISPLAY_MAP.get(qec_method, qec_method)\n",
    "            if method_name not in method_markers:\n",
    "                method_markers[method_name] = marker_map[qec_method]\n",
    "    \n",
    "    # Set up plot appearance\n",
    "    ax.set_title(\"Loss Ratio vs. Distance by Error Combination\", fontsize=16)\n",
    "    ax.set_xlabel(\"Distance (km)\", fontsize=14)\n",
    "    ax.set_ylabel(\"Average Loss Ratio\", fontsize=14)\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.set_xlim(left=0)\n",
    "    ax.grid(True, linestyle=':', alpha=0.7)\n",
    "    \n",
    "    # Create a better legend\n",
    "    from matplotlib.lines import Line2D\n",
    "    \n",
    "    # Create custom legend elements\n",
    "    legend_elements = []\n",
    "    \n",
    "    # Add error types\n",
    "    for name, line in error_lines.items():\n",
    "        legend_elements.append(Line2D([0], [0], color=line.get_color(), lw=2, label=name))\n",
    "    \n",
    "    # Add QEC methods\n",
    "    for name, marker in method_markers.items():\n",
    "        legend_elements.append(Line2D([0], [0], marker=marker, color='gray', linestyle='None',\n",
    "                                     markersize=8, label=name))\n",
    "    \n",
    "    ax.legend(handles=legend_elements, loc='best', fontsize=10, framealpha=0.9,\n",
    "             bbox_to_anchor=(1.02, 1), borderaxespad=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, \"loss_vs_distance_all.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# --- Add new function for fiber parameter analysis ---\n",
    "def plot_fiber_params_analysis(df, plots_subdir=\"5_fiber_params_analysis\"):\n",
    "    \"\"\"\n",
    "    Creates plots analyzing the effect of fiber loss parameters:\n",
    "    1. Fidelity vs p_loss_init\n",
    "    2. Fidelity vs p_loss_length\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Plotting Fidelity vs. Fiber Loss Parameters ---\")\n",
    "    plot_dir = os.path.join(PLOTS_DIR, plots_subdir)\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    \n",
    "    # Only include fiber loss experiments\n",
    "    fiber_df = df[df['error_combo'] == 'fibre_loss'].copy()\n",
    "    if fiber_df.empty:\n",
    "        print(\"  No fiber loss data found for parameter analysis.\")\n",
    "        return\n",
    "        \n",
    "    # Extract parameters\n",
    "    fiber_df['p_loss_init'] = fiber_df['error_params'].apply(\n",
    "        lambda p: p.get('p_loss_init', None) if isinstance(p, dict) else None)\n",
    "    fiber_df['p_loss_length'] = fiber_df['error_params'].apply(\n",
    "        lambda p: p.get('p_loss_length', None) if isinstance(p, dict) else None)\n",
    "    \n",
    "    # Drop rows with missing parameters\n",
    "    fiber_df = fiber_df.dropna(subset=['p_loss_init', 'p_loss_length'])\n",
    "    \n",
    "    if fiber_df.empty:\n",
    "        print(\"  Unable to extract fiber parameters from data.\")\n",
    "        return\n",
    "    \n",
    "    # --- 1. Plot Fidelity vs p_loss_init ---\n",
    "    print(\"  Plotting fidelity vs p_loss_init...\")\n",
    "    \n",
    "    # Get unique values for faceting\n",
    "    p_lens = sorted(fiber_df['p_loss_length'].unique())\n",
    "    distances = sorted(fiber_df['distance'].unique())\n",
    "    \n",
    "    if len(p_lens) > 1 and len(distances) > 0:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        ax = plt.gca()\n",
    "        \n",
    "        # Set up color and marker schemes\n",
    "        colors = plt.cm.viridis(np.linspace(0, 0.85, len(distances)))\n",
    "        dist_colors = {d: colors[i] for i, d in enumerate(distances)}\n",
    "        \n",
    "        qec_methods = sorted(fiber_df['qec_method'].unique())\n",
    "        markers = ['o', 's', '^', 'd', '*']\n",
    "        qec_markers = {qec: markers[i % len(markers)] for i, qec in enumerate(qec_methods)}\n",
    "        \n",
    "        linestyles = ['-', '--', '-.', ':']\n",
    "        p_len_lines = {p_len: linestyles[i % len(linestyles)] for i, p_len in enumerate(p_lens)}\n",
    "        \n",
    "        # Track for legend\n",
    "        dist_handles = {}\n",
    "        method_handles = {}\n",
    "        p_len_handles = {}\n",
    "        \n",
    "        # For each p_loss_length value\n",
    "        for p_len in p_lens:\n",
    "            # For each distance\n",
    "            for dist in distances:\n",
    "                # For each QEC method\n",
    "                for qec_method in qec_methods:\n",
    "                    subset = fiber_df[(fiber_df['p_loss_length'] == p_len) & \n",
    "                                      (fiber_df['distance'] == dist) & \n",
    "                                      (fiber_df['qec_method'] == qec_method)]\n",
    "                    \n",
    "                    if len(subset) < 2:\n",
    "                        continue\n",
    "                    \n",
    "                    # Group by p_loss_init\n",
    "                    grouped = subset.groupby('p_loss_init').agg(\n",
    "                        avg_fid_raw=('avg_fidelity_raw', 'mean'),\n",
    "                        std_fid_raw=('avg_fidelity_raw', 'std'),\n",
    "                        avg_fid_adj=('avg_fidelity_adj', 'mean'),\n",
    "                        std_fid_adj=('avg_fidelity_adj', 'std')\n",
    "                    ).reset_index()\n",
    "                    \n",
    "                    # Sort by p_loss_init\n",
    "                    grouped = grouped.sort_values('p_loss_init')\n",
    "                    \n",
    "                    if len(grouped) < 2:\n",
    "                        continue\n",
    "                    \n",
    "                    # Plot raw fidelity\n",
    "                    line_raw, = ax.plot(grouped['p_loss_init'], grouped['avg_fid_raw'],\n",
    "                                      marker=qec_markers[qec_method], \n",
    "                                      linestyle=p_len_lines[p_len],\n",
    "                                      color=dist_colors[dist], \n",
    "                                      markersize=8, linewidth=2,\n",
    "                                      label=f\"Dist={dist}, p_len={p_len}, {METHOD_DISPLAY_MAP.get(qec_method, qec_method)} (Raw)\")\n",
    "                    \n",
    "                    # Plot adjusted fidelity (slightly transparent)\n",
    "                    line_adj, = ax.plot(grouped['p_loss_init'], grouped['avg_fid_adj'],\n",
    "                                      marker=qec_markers[qec_method], \n",
    "                                      linestyle=p_len_lines[p_len],\n",
    "                                      color=dist_colors[dist], \n",
    "                                      markersize=8, linewidth=2, alpha=0.5,\n",
    "                                      label=f\"Dist={dist}, p_len={p_len}, {METHOD_DISPLAY_MAP.get(qec_method, qec_method)} (Adj.)\")\n",
    "                    \n",
    "                    # Track for legend\n",
    "                    dist_handles[dist] = dist_colors[dist]\n",
    "                    method_handles[METHOD_DISPLAY_MAP.get(qec_method, qec_method)] = qec_markers[qec_method]\n",
    "                    p_len_handles[p_len] = p_len_lines[p_len]\n",
    "        \n",
    "        # Set up plot appearance\n",
    "        ax.set_title(r\"Fidelity vs. Initial Loss Probability ($p_{loss\\_init}$)\", fontsize=16)\n",
    "        ax.set_xlabel(r\"Initial Loss Probability ($p_{loss\\_init}$)\", fontsize=14)\n",
    "        ax.set_ylabel(\"Average Fidelity\", fontsize=14)\n",
    "        ax.set_ylim(0, 1.05)\n",
    "        ax.grid(True, linestyle=':', alpha=0.7)\n",
    "        \n",
    "        # Create multi-part legend\n",
    "        from matplotlib.lines import Line2D\n",
    "        \n",
    "        legend_elements = []\n",
    "        \n",
    "        # Distance legend elements\n",
    "        for dist, color in dist_handles.items():\n",
    "            legend_elements.append(Line2D([0], [0], color=color, lw=2, \n",
    "                                        label=f\"Distance: {dist} km\"))\n",
    "        \n",
    "        # Line style legend elements (p_loss_length)\n",
    "        for p_len, ls in p_len_handles.items():\n",
    "            legend_elements.append(Line2D([0], [0], color='gray', linestyle=ls, lw=2,\n",
    "                                        label=f\"Loss/km: {p_len} dB/km\"))\n",
    "        \n",
    "        # QEC method legend elements\n",
    "        for method, marker in method_handles.items():\n",
    "            legend_elements.append(Line2D([0], [0], color='gray', marker=marker, linestyle='None',\n",
    "                                        markersize=8, label=f\"QEC: {method}\"))\n",
    "        \n",
    "        # Fidelity type legend elements\n",
    "        legend_elements.append(Line2D([0], [0], color='gray', lw=2, alpha=1.0,\n",
    "                                    label='Raw Fidelity'))\n",
    "        legend_elements.append(Line2D([0], [0], color='gray', lw=2, alpha=0.5,\n",
    "                                    label='Adjusted Fidelity'))\n",
    "        \n",
    "        ax.legend(handles=legend_elements, loc='upper right', fontsize=9, \n",
    "                 framealpha=0.9, ncol=2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(plot_dir, \"fidelity_vs_p_loss_init.png\"), dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    # --- 2. Plot Fidelity vs p_loss_length ---\n",
    "    print(\"  Plotting fidelity vs p_loss_length...\")\n",
    "    \n",
    "    # Get unique values for faceting\n",
    "    p_inits = sorted(fiber_df['p_loss_init'].unique())\n",
    "    \n",
    "    if len(p_inits) > 1 and len(distances) > 0:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        ax = plt.gca()\n",
    "        \n",
    "        # Set up color and marker schemes\n",
    "        colors = plt.cm.viridis(np.linspace(0, 0.85, len(distances)))\n",
    "        dist_colors = {d: colors[i] for i, d in enumerate(distances)}\n",
    "        \n",
    "        qec_methods = sorted(fiber_df['qec_method'].unique())\n",
    "        markers = ['o', 's', '^', 'd', '*']\n",
    "        qec_markers = {qec: markers[i % len(markers)] for i, qec in enumerate(qec_methods)}\n",
    "        \n",
    "        linestyles = ['-', '--', '-.', ':']\n",
    "        p_init_lines = {p_init: linestyles[i % len(linestyles)] for i, p_init in enumerate(p_inits)}\n",
    "        \n",
    "        # Track for legend\n",
    "        dist_handles = {}\n",
    "        method_handles = {}\n",
    "        p_init_handles = {}\n",
    "        \n",
    "        # For each p_loss_init value\n",
    "        for p_init in p_inits:\n",
    "            # For each distance\n",
    "            for dist in distances:\n",
    "                # For each QEC method\n",
    "                for qec_method in qec_methods:\n",
    "                    subset = fiber_df[(fiber_df['p_loss_init'] == p_init) & \n",
    "                                      (fiber_df['distance'] == dist) & \n",
    "                                      (fiber_df['qec_method'] == qec_method)]\n",
    "                    \n",
    "                    if len(subset) < 2:\n",
    "                        continue\n",
    "                    \n",
    "                    # Group by p_loss_length\n",
    "                    grouped = subset.groupby('p_loss_length').agg(\n",
    "                        avg_fid_raw=('avg_fidelity_raw', 'mean'),\n",
    "                        std_fid_raw=('avg_fidelity_raw', 'std'),\n",
    "                        avg_fid_adj=('avg_fidelity_adj', 'mean'),\n",
    "                        std_fid_adj=('avg_fidelity_adj', 'std')\n",
    "                    ).reset_index()\n",
    "                    \n",
    "                    # Sort by p_loss_length\n",
    "                    grouped = grouped.sort_values('p_loss_length')\n",
    "                    \n",
    "                    if len(grouped) < 2:\n",
    "                        continue\n",
    "                    \n",
    "                    # Plot raw fidelity\n",
    "                    line_raw, = ax.plot(grouped['p_loss_length'], grouped['avg_fid_raw'],\n",
    "                                      marker=qec_markers[qec_method], \n",
    "                                      linestyle=p_init_lines[p_init],\n",
    "                                      color=dist_colors[dist], \n",
    "                                      markersize=8, linewidth=2,\n",
    "                                      label=f\"Dist={dist}, p_init={p_init}, {METHOD_DISPLAY_MAP.get(qec_method, qec_method)} (Raw)\")\n",
    "                    \n",
    "                    # Plot adjusted fidelity (slightly transparent)\n",
    "                    line_adj, = ax.plot(grouped['p_loss_length'], grouped['avg_fid_adj'],\n",
    "                                      marker=qec_markers[qec_method], \n",
    "                                      linestyle=p_init_lines[p_init],\n",
    "                                      color=dist_colors[dist], \n",
    "                                      markersize=8, linewidth=2, alpha=0.5,\n",
    "                                      label=f\"Dist={dist}, p_init={p_init}, {METHOD_DISPLAY_MAP.get(qec_method, qec_method)} (Adj.)\")\n",
    "                    \n",
    "                    # Track for legend\n",
    "                    dist_handles[dist] = dist_colors[dist]\n",
    "                    method_handles[METHOD_DISPLAY_MAP.get(qec_method, qec_method)] = qec_markers[qec_method]\n",
    "                    p_init_handles[p_init] = p_init_lines[p_init]\n",
    "        \n",
    "        # Set up plot appearance\n",
    "        ax.set_title(r\"Fidelity vs. Loss per Length ($p_{loss\\_length}$)\", fontsize=16)\n",
    "        ax.set_xlabel(r\"Loss per Length (dB/km)\", fontsize=14)\n",
    "        ax.set_ylabel(\"Average Fidelity\", fontsize=14)\n",
    "        ax.set_ylim(0, 1.05)\n",
    "        ax.grid(True, linestyle=':', alpha=0.7)\n",
    "        \n",
    "        # Create multi-part legend\n",
    "        from matplotlib.lines import Line2D\n",
    "        \n",
    "        legend_elements = []\n",
    "        \n",
    "        # Distance legend elements\n",
    "        for dist, color in dist_handles.items():\n",
    "            legend_elements.append(Line2D([0], [0], color=color, lw=2, \n",
    "                                        label=f\"Distance: {dist} km\"))\n",
    "        \n",
    "        # Line style legend elements (p_loss_init)\n",
    "        for p_init, ls in p_init_handles.items():\n",
    "            legend_elements.append(Line2D([0], [0], color='gray', linestyle=ls, lw=2,\n",
    "                                        label=f\"Init Loss: {p_init}\"))\n",
    "        \n",
    "        # QEC method legend elements\n",
    "        for method, marker in method_handles.items():\n",
    "            legend_elements.append(Line2D([0], [0], color='gray', marker=marker, linestyle='None',\n",
    "                                        markersize=8, label=f\"QEC: {method}\"))\n",
    "        \n",
    "        # Fidelity type legend elements\n",
    "        legend_elements.append(Line2D([0], [0], color='gray', lw=2, alpha=1.0,\n",
    "                                    label='Raw Fidelity'))\n",
    "        legend_elements.append(Line2D([0], [0], color='gray', lw=2, alpha=0.5,\n",
    "                                    label='Adjusted Fidelity'))\n",
    "        \n",
    "        ax.legend(handles=legend_elements, loc='upper right', fontsize=9, \n",
    "                 framealpha=0.9, ncol=2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(plot_dir, \"fidelity_vs_p_loss_length.png\"), dpi=300)\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73f95be1-1715-4b0d-b807-a3b077c1bf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading distance experiment data from: distance_qec_fiber_loss\n",
      "Finished loading. Loaded 149 experiment configurations from metadata.\n",
      "Loaded 149 experiment configurations.\n",
      "\n",
      "Example loaded distance data point:\n",
      "{'initial_state': '+', 'qec_method': 'none', 'distance': 10.0, 'error_combo': 'fibre_loss_plus_phase_damping', 'error_params': {'p_loss_init': 0.05, 'p_loss_length': 0.16, 'sec_gamma': 0.01}, 'param_string': 'p_loss_init=0.05, p_loss_length=0.16, sec_gamma=0.01', 'avg_fidelity_raw': 0.997005988023952, 'std_fidelity_raw': 0.0547175655164582, 'avg_fidelity_adj': 0.5014880418803112, 'loss_ratio': 0.49700598802395207, 'loss_count': 166, 'total_runs': 334, 'filename_base': '+_none_d10.0_p_loss_init_0.05_p_loss_length_0.16_sec_gamma_0.01.csv'}\n",
      "\n",
      "--- Plot 1: Fidelity vs Error Combination ---\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'groupby'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_distance_metrics[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Call all the analysis functions\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m plot_fidelity_by_error_combo(df_distance_metrics)\n\u001b[1;32m     18\u001b[0m plot_fidelity_vs_distance_combined(df_distance_metrics)\n\u001b[1;32m     19\u001b[0m plot_loss_vs_distance_combined(df_distance_metrics)\n",
      "Cell \u001b[0;32mIn[20], line 276\u001b[0m, in \u001b[0;36mplot_fidelity_by_error_combo\u001b[0;34m(df, plots_subdir)\u001b[0m\n\u001b[1;32m    273\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(plot_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# Aggregate fidelities, calculating mean and std dev of the means across runs\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m agg_data \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_combo\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg(\n\u001b[1;32m    277\u001b[0m     mean_raw\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_fidelity_raw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    278\u001b[0m     std_raw\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_fidelity_raw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;66;03m# Std dev of the mean fidelities from different configs\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     mean_adj\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_fidelity_adj\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    280\u001b[0m     std_adj\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_fidelity_adj\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Std dev of the mean adjusted fidelities\u001b[39;00m\n\u001b[1;32m    281\u001b[0m )\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# Sort for consistent plotting order (optional)\u001b[39;00m\n\u001b[1;32m    284\u001b[0m agg_data \u001b[38;5;241m=\u001b[39m agg_data\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_adj\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'groupby'"
     ]
    }
   ],
   "source": [
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    configure_plots()\n",
    "    \n",
    "    # Load the data (no need for full data for these plots)\n",
    "    df_distance_metrics = load_distance_qec_data()\n",
    "    \n",
    "    if not df_distance_metrics:\n",
    "        print(\"No distance data loaded, cannot perform analysis.\")\n",
    "    else:\n",
    "        print(f\"Loaded {len(df_distance_metrics)} experiment configurations.\")\n",
    "        if len(df_distance_metrics) > 0:\n",
    "            print(\"\\nExample loaded distance data point:\")\n",
    "            print(df_distance_metrics[0])\n",
    "            \n",
    "            # Call all the analysis functions\n",
    "            plot_fidelity_by_error_combo(df_distance_metrics)\n",
    "            plot_fidelity_vs_distance_combined(df_distance_metrics)\n",
    "            plot_loss_vs_distance_combined(df_distance_metrics)\n",
    "            plot_qec_performance_faceted_by_error(df_distance_metrics)\n",
    "            plot_fiber_params_analysis(df_distance_metrics)\n",
    "            \n",
    "            print(f\"\\nAnalysis complete. Plots saved to: {PLOTS_DIR}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de2d46-9be7-405b-8ffc-e195ffc9798f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
